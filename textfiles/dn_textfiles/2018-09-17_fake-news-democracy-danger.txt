## Title: Fake news: Democracy in danger
## Supertitle: 
## Section: Features
## Date: Monday, September 17, 2018 - 01:00

Fake news: Democracy in danger

In 2014, at the World Economic Forum, the rapid spread of misinformation online was considered the 10th top trend in terms of global significance.
Fake accounts on social media (i.e. those which either do not have a human user behind them, or are run by a human who pretends to be someone else) are the foot soldiers in this form of warfare. They can be used to amplify messaging and force hashtags into the trending lists. On occasion, they can be used to intimidate or block other users.
The online falsehoods and false accounts detailed above can be used in short-term and long-term ways. Short-term uses focus on a specific event, such as a vote, demonstration, natural disaster or security incident, and attempt to achieve an effect by the massive and sudden deployment of false stories or accounts.
Longer-term operations typically focus on promoting or attacking a particular point of view. This can range from partisan and one-sided coverage, through hate speech, and into incitement to violence. In extreme cases, online hate speech can be a contributing factor in individuals’ decision to commit terrorist acts. This was the case of British citizen Darren Osborne, who drove a van into a crowd outside a North London mosque in 2017, and who was found by a judge to have been “exposed to racists and anti-Islam ideology” via Twitter.
For Sri Lanka, election campaigns and tensions between different social, religious, political, economic and ethnic groups are likely to be the main targets of any such attempts, as the campaigns tend to gradually inflame tensions and hollow out the political centre at the expense of the fringes. Relations with neighbouring countries can also be the focus of targeted disinformation or influence campaigns.
We are highly susceptible to organised and deliberate disinformation campaigns trying to interfere with democratic processes, destabilise society and undermine institutions. We are a small and multiracial society that can be easily overwhelmed by a larger adversary taking advantage of our societal fault lines.
An aggressor could attempt to “peel off” one particular ethnic group or religion, using social media and disinformation to appeal (as the case may be) to deeply ingrained historical, cultural issues, setting off one group against others, or even against the government. Data-driven political consultancies (whose methods may involve disinformation) appear to have been engaged by political parties, as well as individual candidates.
A number of responses are needed to deal with this challenge. In all responses, legislation should be the last resort. As far as possible, information, even false information, should remain outside the purview of government. This is essential for the health of democracy.
Amplification networks are best dealt with by the social platforms. Governments should therefore engage with platforms, especially Facebook and Twitter, to find a means by which networks of false, automated or inauthentic accounts, can quickly be shut down.
It is therefore important to educate internet users in the basic principles of digital awareness and hygiene, and to work with the platforms on solutions, rather than against them. Essential skills such as how to identify a bot or a troll can be taught without recourse to sophisticated software or analytical techniques. Such skills are vital for normal users, and particularly for media outlets, which can otherwise amplify fraudulent accounts.
Online insertion points are best dealt with by civil society, researchers and the platforms, working in combination. Researchers can identify websites or social media accounts which repeatedly post information which is demonstrably false; these can then be flagged to the platforms. Given the sheer size of the platforms, it is not practical for them to monitor their content unaided.
Many countries have called for a tough stance to be taken against fake news, including the US, UK and Germany, or to put in place more effective measures to counter fake news. Germany, for example, is considering a draft law that will require social networks, websites, including Facebook, to remove fake news which amounts to illegal content from their platforms. So, make the network itself responsible. Social networks which fail to comply with such a request could face very stiff fines. In Germany, it is being suggested €50 million – that is a lot of money – under the draft legislation.
****
Successful falsehoods tend to have four components
* They have an instant emotional appeal;
* They claim authority by referring to an unimpeachable source;
* They have an insertion point into the information space; and
* They then have an amplification network which passes them on to a broader public. Stories which lack one or more of these elements tend to fail.
****
Combat disinformation
In some countries, the best anti-disinformation websites and portals are run by citizens, journalists, or a coalition of both. In many instances, it is the citizenry and journalists (as well as media experts, branding experts, and marketing consultants) who are better placed to act, and to act quickly, to combat disinformation. Ukraine’s Stopfake.org, which positions itself as public service journalism, is a crowd sourced journalism project that launched in 2014 to combat fake news spreading across the Internet during Ukraine’s crisis in Crimea. The widely-respected site provides fact checking, verifies information, and refutes incorrect reports and propaganda about events in Crimea, which are widely believed to originate from Russia. In Indonesia, the volunteer run Turn Back Hoax, which has been online since 2016, has grown into an important resource for Indonesians to check the veracity of memes and fake stories.
****
Key developments
* First, the number of platforms and channels by which falsehood can be spread has increased radically. On Facebook alone, the number of active monthly users grew from 100 million in Q3, 2008, to over 2 billion in Q4, 2017.
* Second, the relatively low cost of creating an online platform has made it far easier for those who spread falsehoods to look like traditional reporting outlets, without adhering to traditional editorial standards.
* Third, social media have allowed peer-to-peer interactions on an unprecedented scale, allowing malicious actors to bypass traditional editorial verification and spread their falsehoods (literally) unchecked.
* Fourth, the borderless nature of the internet has made it much easier for foreign actors to impersonate internet users in the target country, and thus to infiltrate target communities.
* Fifth, modern editorial techniques have made it progressively easier for malicious actors to create false or misleading content, ranging from photo shopped images to doctored videos which can make a speaker appear to say something they did not.
****
Fact-checking groups
Governments should not seek direct involvement in this process; however, they have a valuable role to play in bringing the tech and analytical communities together to facilitate cooperation. The appearance of authority is best countered by fact-checking groups, which have proliferated in recent years. These have the expertise to expose the various techniques of falsehood, and the reputation to make their work more credible. Many fact-checking and verification operations now exist, such as First Draft, Snopes and Politifact in the U.S., MalditoBulo in Spain, Les Décodeurs of Le Monde in France, the Bellingcat group, the Atlantic Council's Digital Forensic Research Lab and numerous units within major broadcasters such as the BBC. 

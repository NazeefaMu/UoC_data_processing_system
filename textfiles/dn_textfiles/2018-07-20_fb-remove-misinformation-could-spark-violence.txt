## Title: FB to remove misinformation that could spark violence
## Supertitle: 
## Section: Local
## Date: Friday, July 20, 2018 - 01:00

FB to remove misinformation that could spark violence

Facebook, facing growing criticism for posts that have incited violence in countries including Sri Lanka, has said that it would begin removing misinformation that could lead to people being physically harmed.
The policy expands Facebook’s rules about what type of false information it would remove, and comes largely in response to instances in Sri Lanka, Myanmar and India, in which rumours spread on Facebook led to real-world attacks.
The new rules do not apply to Facebook’s other big social media properties; Instagram and WhatsApp.
“We have identified that there is a type of misinformation that is shared in certain countries that can incite underlying tensions and lead to physical harm offline. We have a broader responsibility to not just reduce that type of content, but remove it,” Tessa Lyons, a Facebook product manager, said.
Facebook has been criticised over the way its platform had been used to spread hate speech and false information that led to violence. The company had struggled to balance its belief in free speech with those concerns, particularly in countries where access to the internet was relatively new and mainstream news sources that would counter social media rumours are limited.
In Myanmar, Facebook had been accused by United Nations investigators and human rights groups, of facilitating violence against Rohingya Muslims, a minority ethnic group, by allowing anti-Muslim hate speech and false news.
In Sri Lanka, riots broke out after false news pitted the country’s majority Buddhist community against Muslims. Near-identical social media rumours had also led to attacks in India and Mexico. In many cases, the rumours included no call for violence, but amplified underlying tensions.
In an interview published by the technology news site ‘Recode,’ Facebook Chief Executive Mark Zuckerberg attempted to explain how the company was trying to differentiate between offensive speech—the example he used was people who deny the Holocaust—and false posts that could lead to physical harm.
“I think that there is a terrible situation where there’s underlying sectarian violence and intention. It is clearly the responsibility of all of the players who were involved there,” Zuckerberg said.
While the social media company already has rules in place in which a direct threat of violence or hate speech is removed, it has been hesitant to remove rumours that do not directly violate its content policies.
Under the new rules, Facebook had said it would create partnerships with local civil society groups, to identify misinformation for removal. The new rules are already being put in effect in Sri Lanka, and Lyons said the company hopes to soon introduce them in Myanmar, before expanding elsewhere.
(New York Times)
 
